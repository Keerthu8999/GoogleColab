{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keerthu8999/GoogleColab/blob/main/MyFate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv5qJraepJvB"
      },
      "source": [
        "# Crime Attribute Extraction App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYOpdGW39AW6"
      },
      "source": [
        "##  Part  1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W97ryK1vpJvE"
      },
      "source": [
        "Loading Dataseet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip\n",
        "!ls"
      ],
      "metadata": {
        "id": "CNUVm7SKun84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "iKl4v1WT6SGE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content\")\n",
        "from CoNLL2Spacy import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h9G_oOx6SJN"
      },
      "outputs": [],
      "source": [
        "# Test File\n",
        "file = open(\"/content/Crimetest.txt\", \"r\",encoding = \"utf-8\")\n",
        "valList = []\n",
        "for line in file:\n",
        "    valList.append(line[:-1])\n",
        "valList[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "tokkaRI46X64"
      },
      "outputs": [],
      "source": [
        "TEST_DATA = conll2spacy(valList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfOT4a8S6pnm"
      },
      "outputs": [],
      "source": [
        "# Train File\n",
        "file = open(\"/content/Crimetrain.txt\", \"r\",encoding = \"utf-8\")\n",
        "trainList = []\n",
        "for line in file:\n",
        "    trainList.append(line[:-1])\n",
        "trainList[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tmXFZVQJ60xS"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = conll2spacy(trainList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "n_wZrijEjRaG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "TweFhaxJjtyO"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zANMD5rljij8"
      },
      "outputs": [],
      "source": [
        "lang=\"en\"\n",
        "vectors_loc = \"/content/wiki-news-300d-1M.vec\"\n",
        "nlp = spacy.blank(lang)\n",
        "with open(vectors_loc, \"rb\") as file_:\n",
        "    header = file_.readline()\n",
        "    nr_row, nr_dim = header.split()\n",
        "    nlp.vocab.reset_vectors(width=int(nr_dim))\n",
        "    for line in file_:\n",
        "        line = line.rstrip().decode(\"utf8\")\n",
        "        pieces = line.rsplit(\" \", int(nr_dim))\n",
        "        word = pieces[0]\n",
        "        vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "        nlp.vocab.set_vector(word, vector)  # add the vectors to the vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "# Define the path to the full word vector file\n",
        "full_vectors_loc = \"/content/wiki-news-300d-1M.vec\"\n",
        "\n",
        "# Define the path to the subset file\n",
        "subset_vectors_loc = \"/content/subset_vectors.vec\"\n",
        "\n",
        "# Define the size of the subset (e.g., 100,000)\n",
        "subset_size = 100000\n",
        "\n",
        "# Create a subset of word vectors\n",
        "def create_subset(full_file, subset_file, subset_size):\n",
        "    with open(full_file, \"rb\") as full_file:\n",
        "        with open(subset_file, \"wb\") as subset_file:\n",
        "            # Write the header\n",
        "            header = full_file.readline()\n",
        "            subset_file.write(header)\n",
        "\n",
        "            # Write a subset of vectors\n",
        "            for _ in range(subset_size):\n",
        "                line = full_file.readline()\n",
        "                subset_file.write(line)\n",
        "\n",
        "# Create the subset file\n",
        "create_subset(full_vectors_loc, subset_vectors_loc, subset_size)\n",
        "\n",
        "# Load the subset of word vectors into SpaCy\n",
        "lang = \"en\"\n",
        "nlp = spacy.blank(lang)\n",
        "with open(subset_vectors_loc, \"rb\") as file_:\n",
        "    header = file_.readline()\n",
        "    nr_row, nr_dim = header.split()\n",
        "    nlp.vocab.reset_vectors(width=int(nr_dim))\n",
        "    for line in file_:\n",
        "        line = line.rstrip().decode(\"utf8\")\n",
        "        pieces = line.rsplit(\" \", int(nr_dim))\n",
        "        word = pieces[0]\n",
        "        vector = np.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "        nlp.vocab.set_vector(word, vector)\n",
        "\n",
        "file_path = \"/content/subset_vectors.vec\"\n",
        "\n",
        "# Open the file and count the number of lines\n",
        "with open(file_path, 'r') as file:\n",
        "    num_lines = sum(1 for line in file)\n",
        "\n",
        "print(\"Number of lines in\", file_path, \":\", num_lines)"
      ],
      "metadata": {
        "id": "PAKi-w04v5QE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf931656-27ef-4b97-edf5-84957a0791d2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines in /content/subset_vectors.vec : 100001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuvQpVLPjRaT"
      },
      "outputs": [],
      "source": [
        "text = \"I lost his doctor in patient yesterday\"\n",
        "doc = nlp(text)\n",
        "print(\"similarity btw\",doc[3] , \"and\", doc[5],\" :-\", doc[3].similarity(doc[5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKn6YehgjRap"
      },
      "source": [
        "# Part  2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGY9RoeGjRaq"
      },
      "source": [
        "Steps involved :-\n",
        "1. Loading required library\n",
        "2. Setting up the parameters for traning\n",
        "3. Traning and saving the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "f33b-LXvjRar"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import random # random function for to remove bais in Traning Data\n",
        "\n",
        "# for batch parsing\n",
        "from spacy.util import minibatch, compounding\n",
        "\n",
        "\n",
        "# For evaluateing the model from testing set\n",
        "from spacy.training import *\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cW3dDFWgjRau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "479bd5f2-1d76-420e-b2e9-ddce80fcaad2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    # add labels that will be involved in training\\n    for _, annotations in TRAIN_DATA:\\n         for ent in annotations.get(\\'entities\\'):\\n            ner.add_label(ent[2])\\n\\n    examples = []\\n\\n    for text, annotations in TRAIN_DATA:\\n        doc = nlp(text)\\n        examples.append(Example.from_dict(doc, annotations))\\n\\n    other_pipes = [pipe for pipe in modiner.pipe_names if pipe != \\'ner\\']\\n    with modiner.disable_pipes(*other_pipes):  # only train NER\\n        optimizer = modiner.begin_training()\\n        for itn in range(iterations):\\n            print(\"Starting iteration \" + str(itn))\\n            random.shuffle(TRAIN_DATA)\\n            losses = {}\\n            #batches = minibatch(TRAIN_DATA, size=compounding(2.0, 16.0, 1.01))\\n            #size_of_batches = sys.getsizeof(batches)\\n            #print(\"Size of batches:\", size_of_batches, \"bytes\")\\n            c = 1\\n            for example in tqdm(examples):\\n                print(example)\\n                nlp.update(\\n                    [example],  \\n                    drop=0.5,  \\n                    sgd=optimizer,\\n                    losses=losses)\\n                print(losses)\\n            c += 1\\n\\n            # Evaluating the Current Model Score on test data\\n            results = evaluate(modiner, TEST_DATA)\\n            print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\\n\\n\\n\\n            # loading previous best saved model in start of traning\\n            if f1score == 0.00:\\n                try:\\n                    pnlp = spacy.load(modelName)\\n                    result = evaluate(pnlp, TEST_DATA) # calling evaluate function\\n                    f1score = result[\"ents_f\"]\\n                except:\\n                    print(\"Previous Model not found\")\\n\\n            print(\"Best Sccore :- \",f1score)\\n            print(\"------------------------------------\")\\n            # finding out the best score\\n            if f1score < results[\"ents_f\"]:\\n                f1score = results[\"ents_f\"]\\n\\n                # Save our trained Model if the score if grater than best score else no change in previous model\\n                modiner.to_disk(modelName)\\n\\n    print(\"-----Best Model is Saved-----\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "def train_spacy(TRAIN_DATA,TEST_DATA,iterations,droprate = 0.5,modelName = \"modelTrained\"):\n",
        "\n",
        "    lang=\"en\"\n",
        "    vectors_loc = \"/content/subset_vectors.vec\"\n",
        "    modiner = spacy.blank(lang)\n",
        "    with open(vectors_loc, \"rb\") as file_:\n",
        "        header = file_.readline()\n",
        "        nr_row, nr_dim = header.split()\n",
        "        modiner.vocab.reset_vectors(width=int(nr_dim))\n",
        "        for line in file_:\n",
        "            line = line.rstrip().decode(\"utf8\")\n",
        "            pieces = line.rsplit(\" \", int(nr_dim))\n",
        "            word = pieces[0]\n",
        "            vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "            modiner.vocab.set_vector(word, vector)  # add the vectors to the vocab\n",
        "    ner = nlp.create_pipe(\"ner\")\n",
        "    if 'ner' not in modiner.pipe_names:\n",
        "        modiner.add_pipe(\"ner\", last=True)\n",
        "\n",
        "    # setting up f1score\n",
        "    f1score = 0.0000\n",
        "\n",
        "    from spacy.training import Example\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "        for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    examples = []\n",
        "\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        doc = nlp(text)\n",
        "        examples.append(Example.from_dict(doc, annotations))\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(100):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            for example in tqdm(examples):\n",
        "                nlp.update(\n",
        "                    [example],\n",
        "                    drop=0.5,\n",
        "                    sgd=optimizer,\n",
        "                    losses=losses)\n",
        "            print(losses)\n",
        "\n",
        "'''\n",
        "    # add labels that will be involved in training\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    examples = []\n",
        "\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        doc = nlp(text)\n",
        "        examples.append(Example.from_dict(doc, annotations))\n",
        "\n",
        "    other_pipes = [pipe for pipe in modiner.pipe_names if pipe != 'ner']\n",
        "    with modiner.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = modiner.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            print(\"Starting iteration \" + str(itn))\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            #batches = minibatch(TRAIN_DATA, size=compounding(2.0, 16.0, 1.01))\n",
        "            #size_of_batches = sys.getsizeof(batches)\n",
        "            #print(\"Size of batches:\", size_of_batches, \"bytes\")\n",
        "            c = 1\n",
        "            for example in tqdm(examples):\n",
        "                print(example)\n",
        "                nlp.update(\n",
        "                    [example],\n",
        "                    drop=0.5,\n",
        "                    sgd=optimizer,\n",
        "                    losses=losses)\n",
        "                print(losses)\n",
        "            c += 1\n",
        "\n",
        "            # Evaluating the Current Model Score on test data\n",
        "            results = evaluate(modiner, TEST_DATA)\n",
        "            print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
        "\n",
        "\n",
        "\n",
        "            # loading previous best saved model in start of traning\n",
        "            if f1score == 0.00:\n",
        "                try:\n",
        "                    pnlp = spacy.load(modelName)\n",
        "                    result = evaluate(pnlp, TEST_DATA) # calling evaluate function\n",
        "                    f1score = result[\"ents_f\"]\n",
        "                except:\n",
        "                    print(\"Previous Model not found\")\n",
        "\n",
        "            print(\"Best Sccore :- \",f1score)\n",
        "            print(\"------------------------------------\")\n",
        "            # finding out the best score\n",
        "            if f1score < results[\"ents_f\"]:\n",
        "                f1score = results[\"ents_f\"]\n",
        "\n",
        "                # Save our trained Model if the score if grater than best score else no change in previous model\n",
        "                modiner.to_disk(modelName)\n",
        "\n",
        "    print(\"-----Best Model is Saved-----\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "xRX87HJnjRay"
      },
      "outputs": [],
      "source": [
        "'''from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "def evaluate(ner_model, examples):\n",
        "    scorer = Scorer()\n",
        "    for input_, annotations in examples:\n",
        "        tags = []\n",
        "        # loading text\n",
        "        doc_gold_text = ner_model.make_doc(input_)\n",
        "\n",
        "        # loading all tags for that text\n",
        "        for ent in annotations.get('entities'):\n",
        "            start, end, label = ent\n",
        "            tags.append((start, end, label))\n",
        "\n",
        "        # Evaluating the tags\n",
        "        gold = Example.from_dict(doc_gold_text, {\"entities\": tags})\n",
        "        pred_value = ner_model(input_)\n",
        "        scorer.score(pred_value, gold)\n",
        "\n",
        "    return scorer.scores\n",
        "'''\n",
        "'''\n",
        "from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "def evaluate(ner_model, examples):\n",
        "  scorer = Scorer()\n",
        "  for input_, annotations in examples:\n",
        "      tags = []\n",
        "      # loading text\n",
        "      doc_gold_text = ner_model.make_doc(input_)\n",
        "\n",
        "      # loading all tags for that text\n",
        "      for ent in annotations.get('entities'):\n",
        "          start, end, label = ent\n",
        "          tags.append((start, end, label))\n",
        "\n",
        "      # Constructing the gold standard Example object\n",
        "      gold_entities = [{\"start\": start, \"end\": end, \"label\": label} for start, end, label in tags]\n",
        "      gold = Example.from_dict(doc_gold_text, {\"entities\": gold_entities})\n",
        "\n",
        "      # Getting the predicted value\n",
        "      pred_value = ner_model(input_)\n",
        "\n",
        "      # Evaluating the tags\n",
        "      scorer.score(pred_value, gold)\n",
        "\n",
        "    return scorer.scores\n",
        "'''\n",
        "from spacy.training import Example\n",
        "def echa(ner_model, testing_data):\n",
        "    scorer = Scorer()\n",
        "    examples = []\n",
        "    for input_, annot in testing_data:\n",
        "        # Convert input text to spaCy Doc\n",
        "        doc = ner_model.make_doc(input_)\n",
        "\n",
        "        # Convert annotations to spaCy format\n",
        "        entities = []\n",
        "        for start, end, label in annot['entities']:\n",
        "            entities.append((start, end, label))\n",
        "        gold_entities = {\"entities\": entities}\n",
        "\n",
        "        # Create Example object\n",
        "        example = Example.from_dict(doc, gold_entities)\n",
        "\n",
        "        # Apply ner_model to the Doc\n",
        "        predicted_doc = ner_model(doc)\n",
        "        example.predicted = predicted_doc\n",
        "        examples.append(example)\n",
        "\n",
        "    return scorer.score(examples)\n",
        "def evaluate(ner_model, testing_data):\n",
        "  print(ner_model)\n",
        "  testing_data = TEST_DATA\n",
        "  ner_model = spacy.blank(lang)\n",
        "  ner = nlp.create_pipe(\"ner\")\n",
        "  if 'ner' not in ner_model.pipe_names:\n",
        "      ner_model.add_pipe(\"ner\", last=True)\n",
        "\n",
        "  ner_model.initialize()\n",
        "  scorer = Scorer()\n",
        "  examples = []\n",
        "  for input_, annot in testing_data:\n",
        "      # Convert input text\n",
        "\n",
        "      to spaCy Doc\n",
        "      doc = ner_model.make_doc(input_)\n",
        "\n",
        "      # Convert annotations to spaCy format\n",
        "      entities = []\n",
        "      for start, end, label in annot['entities']:\n",
        "          entities.append((start, end, label))\n",
        "      gold_entities = {\"entities\": entities}\n",
        "\n",
        "      # Create Example object\n",
        "      example = Example.from_dict(doc, gold_entities)\n",
        "\n",
        "      # Apply ner_model to the Doc\n",
        "      predicted_doc = ner_model(doc)\n",
        "      example.predicted = predicted_doc\n",
        "      examples.append(example)\n",
        "\n",
        "  print(scorer.score(examples))\n",
        "  return scorer.score(examples)\n",
        "\n",
        "\n",
        "def evaluate1(ner_model, testing_data):\n",
        "    # Initialize a scorer to compute evaluation metrics\n",
        "    scorer = Scorer()\n",
        "\n",
        "    # Iterate over each testing example\n",
        "    for input_text, annotations in testing_data:\n",
        "        # Convert input text to a spaCy Doc object\n",
        "        doc_gold_text = ner_model.make_doc(input_)\n",
        "\n",
        "        # Create a spaCy Example object with gold annotations\n",
        "        gold_entities = {\"entities\": annotations['entities']}\n",
        "        gold_example = Example.from_dict(doc_gold_text, gold_entities)\n",
        "\n",
        "        # Predict named entities using the NER model\n",
        "        predicted_entities = ner_model(input_text).to_json()['ents']\n",
        "\n",
        "        # Create a spaCy Example object with predicted entities\n",
        "        predicted_example = Example.from_dict(doc_gold_text, {\"entities\": predicted_entities})\n",
        "\n",
        "        # Update the scorer with the predicted and gold annotations\n",
        "        scorer.score(predicted_example, gold_example)\n",
        "\n",
        "    # Compute and return evaluation scores\n",
        "    evaluation_scores = scorer.scores\n",
        "    return evaluation_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Yz4LfssbjRa0"
      },
      "outputs": [],
      "source": [
        "def loadNERModel(modelName = \"modelTrained\"):\n",
        "    nlp = spacy.load(modelName)\n",
        "    return nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "guqS2EGBjRa3"
      },
      "outputs": [],
      "source": [
        "def score(model,TEST_DATA):\n",
        "    result = evaluate(model, TEST_DATA) # calling evaluate function\n",
        "    f1score = result[\"ents_f\"]\n",
        "    precision = result[\"ents_p\"]\n",
        "    recall = result[\"ents_r\"]\n",
        "    print(\"F1 score of Model is :-\",f1score)\n",
        "    print(\"Precision of Model is :-\",precision)\n",
        "    print(\"Recall of Model is :-\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.training import Example\n",
        "f1score = 0.0000\n",
        "modelName = \"modelTrained\"\n",
        "lang=\"en\"\n",
        "vectors_loc = \"/content/subset_vectors.vec\"\n",
        "modiner = spacy.blank(lang)\n",
        "with open(vectors_loc, \"rb\") as file_:\n",
        "    header = file_.readline()\n",
        "    nr_row, nr_dim = header.split()\n",
        "    modiner.vocab.reset_vectors(width=int(nr_dim))\n",
        "    for line in file_:\n",
        "        line = line.rstrip().decode(\"utf8\")\n",
        "        pieces = line.rsplit(\" \", int(nr_dim))\n",
        "        word = pieces[0]\n",
        "        vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "        modiner.vocab.set_vector(word, vector)  # add the vectors to the vocab\n",
        "ner = nlp.create_pipe(\"ner\")\n",
        "if 'ner' not in modiner.pipe_names:\n",
        "    modiner.add_pipe(\"ner\", last=True)\n",
        "\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get('entities'):\n",
        "      ner.add_label(ent[2])\n",
        "\n",
        "examples = []\n",
        "\n",
        "for text, annotations in TRAIN_DATA:\n",
        "    doc = nlp(text)\n",
        "    examples.append(Example.from_dict(doc, annotations))\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with modiner.disable_pipes(*other_pipes):  # only train NER\n",
        "    optimizer = modiner.begin_training()\n",
        "    for itn in range(3):\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        for example in tqdm(examples):\n",
        "            modiner.update(\n",
        "                [example],\n",
        "                drop=0.5,\n",
        "                losses=losses)\n",
        "        print(losses)\n",
        "        results = evaluate1(modiner, TEST_DATA)\n",
        "        print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
        "        #print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
        "        if f1score == 0.00:\n",
        "            try:\n",
        "                pnlp = spacy.load(modelName)\n",
        "                result = evaluate1(pnlp, TEST_DATA) # calling evaluate function\n",
        "                f1score = result[\"ents_f\"]\n",
        "            except:\n",
        "                print(\"Previous Model not found\")\n",
        "\n",
        "        print(\"Best Sccore :- \",f1score)\n",
        "        print(\"------------------------------------\")\n",
        "        if f1score < results[\"ents_f\"]:\n",
        "            f1score = results[\"ents_f\"]\n",
        "            modiner.to_disk(modelName)\n",
        "\n",
        "    print(\"-----Best Model is Saved-----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsoJwEDjHCB2",
        "outputId": "d66dbc03-60bc-464c-fcb3-eb5b55c4991f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36418/36418 [23:51<00:00, 25.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ner': 82342.59714538547}\n",
            "<spacy.lang.en.English object at 0x78e0309f38e0>\n",
            "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': None, 'sents_r': None, 'sents_f': None, 'tag_acc': None, 'pos_acc': None, 'morph_acc': None, 'morph_micro_p': None, 'morph_micro_r': None, 'morph_micro_f': None, 'morph_per_feat': None, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 0.0, 'ents_r': 0.0, 'ents_f': 0.0, 'ents_per_type': {'B-Crime': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-geo': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-gpe': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-geo': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-per': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-per': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-org': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-org': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-tim': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-eve': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-eve': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-tim': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-Crime': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-art': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-art': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-gpe': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-nat': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-nat': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'cats_score': 0.0, 'cats_score_desc': 'macro F', 'cats_micro_p': 0.0, 'cats_micro_r': 0.0, 'cats_micro_f': 0.0, 'cats_macro_p': 0.0, 'cats_macro_r': 0.0, 'cats_macro_f': 0.0, 'cats_macro_auc': 0.0, 'cats_f_per_type': {}, 'cats_auc_per_type': {}}\n",
            "Current Score :- 0.0 Precision  :- 0.0 Recall  :- 0.0\n",
            "Previous Model not found\n",
            "Best Sccore :-  0.0\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 32931/36418 [21:41<02:37, 22.09it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZijYn1k6pJvL"
      },
      "outputs": [],
      "source": [
        "# traning the model with 100 iterations\n",
        "\n",
        "\n",
        "train_spacy(TRAIN_DATA,TEST_DATA, 1,droprate = 0.55, modelName = \"CrimeNER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afOFw7bCjRbB"
      },
      "outputs": [],
      "source": [
        "# loading the saved model\n",
        "pnlp = loadNERModel(\"CrimeNER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQLM6egTpJvL",
        "outputId": "fe4812f7-265f-4aae-fc2b-f7f7d5cb747f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score of Model is :- 86.47551444580847\n",
            "Precision of Model is :- 87.0393931979447\n",
            "Recall of Model is :- 85.91889476607976\n"
          ]
        }
      ],
      "source": [
        "# calculating the score of the model\n",
        "score(pnlp,TEST_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq3fKUBujRbI"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvywkBOA9AY2",
        "outputId": "1f7365cc-fc1b-403e-865b-547d44f35bcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">he was \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    killed\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " due to \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    harassment\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('he was killed due to harassment')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OHvJTkjpJvM",
        "outputId": "14dde88b-0d80-4299-daba-40a9811b4df7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A woman was \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    assault\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " by two men near \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shahdara\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('A woman was assault by two men near Shahdara')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tyb4RAWpJvM",
        "outputId": "78e8a86d-01a1-42d3-b917-18c90ec5379c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Pooja\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-per</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    I\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
              "</mark>\n",
              " was near \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Domino-pizza\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-org</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Pinjore\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              " a man on bike \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    snatched\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " my purse</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('My name is Pooja I was near Domino-pizza in Pinjore a man on bike snatched my purse')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KnyiH09pJvM",
        "outputId": "d54f27e0-6a90-4b43-fc26-00ae70e417ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amit\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-per</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    I\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
              "</mark>\n",
              " saw a woman \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    killing\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " a dog on \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    15th\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-tim</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    july\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-tim</span>\n",
              "</mark>\n",
              " near \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kalujhanda\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('My name is Amit I saw a woman killing a dog on 15th july near Kalujhanda')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00JgazqIpJvN",
        "outputId": "c8f23d6d-06f4-4e51-a91e-be9a04f7a47f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A car \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hit\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " me at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mansarovar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Park\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-geo</span>\n",
              "</mark>\n",
              " at 5pm wraped</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('A car hit me at Mansarovar Park at 5pm wraped')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqsoj-LLpJvN",
        "outputId": "10afde33-b60c-44f3-f2ed-c04ec6a69631"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Yesterday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-tim</span>\n",
              "</mark>\n",
              " there was incident of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    theft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " near my house</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('Yesterday there was incident of theft near my house')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMsA-3SmpJvO",
        "outputId": "e51273d0-6e1a-44ef-9255-3e4ff983881d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A man slapped a girl in the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sadar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              " market</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('A man slapped a girl in the Sadar market')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTmSz1WApJvO",
        "outputId": "56d70c47-b5ea-428e-f434-a122ee14cacf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Shreya\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  warnings.warn(Warnings.W006)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">  </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhOiJ5nTpJvO"
      },
      "outputs": [],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLYlUpmVpJvP"
      },
      "outputs": [],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55BBsXt2pJvP"
      },
      "outputs": [],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX0sxFLCpJvP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0begjTbspJvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOW7ZtPupJvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_LJMq_TpJvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axuRCCUGpJvR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIWrMATnpJvR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnj-YF-4pJvR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}