{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keerthu8999/GoogleColab/blob/main/Copy_of_CrimeNeR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv5qJraepJvB"
      },
      "source": [
        "# Crime Attribute Extraction App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYOpdGW39AW6"
      },
      "source": [
        "##  Part  1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W97ryK1vpJvE"
      },
      "source": [
        "Loading Dataseet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip\n",
        "!ls"
      ],
      "metadata": {
        "id": "CNUVm7SKun84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iKl4v1WT6SGE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content\")\n",
        "from CoNLL2Spacy import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h9G_oOx6SJN"
      },
      "outputs": [],
      "source": [
        "# Test File\n",
        "file = open(\"/content/Crimetest.txt\", \"r\",encoding = \"utf-8\")\n",
        "valList = []\n",
        "for line in file:\n",
        "    valList.append(line[:-1])\n",
        "valList[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tokkaRI46X64"
      },
      "outputs": [],
      "source": [
        "TEST_DATA = conll2spacy(valList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfOT4a8S6pnm"
      },
      "outputs": [],
      "source": [
        "# Train File\n",
        "file = open(\"/content/Crimetrain.txt\", \"r\",encoding = \"utf-8\")\n",
        "trainList = []\n",
        "for line in file:\n",
        "    trainList.append(line[:-1])\n",
        "trainList[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tmXFZVQJ60xS"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = conll2spacy(trainList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n_wZrijEjRaG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TweFhaxJjtyO"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zANMD5rljij8"
      },
      "outputs": [],
      "source": [
        "lang=\"en\"\n",
        "vectors_loc = \"/content/wiki-news-300d-1M.vec\"\n",
        "nlp = spacy.blank(lang)\n",
        "with open(vectors_loc, \"rb\") as file_:\n",
        "    header = file_.readline()\n",
        "    nr_row, nr_dim = header.split()\n",
        "    nlp.vocab.reset_vectors(width=int(nr_dim))\n",
        "    for line in file_:\n",
        "        line = line.rstrip().decode(\"utf8\")\n",
        "        pieces = line.rsplit(\" \", int(nr_dim))\n",
        "        word = pieces[0]\n",
        "        vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "        nlp.vocab.set_vector(word, vector)  # add the vectors to the vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "# Define the path to the full word vector file\n",
        "full_vectors_loc = \"/content/wiki-news-300d-1M.vec\"\n",
        "\n",
        "# Define the path to the subset file\n",
        "subset_vectors_loc = \"/content/subset_vectors.vec\"\n",
        "\n",
        "# Define the size of the subset (e.g., 100,000)\n",
        "subset_size = 5000\n",
        "\n",
        "# Create a subset of word vectors\n",
        "def create_subset(full_file, subset_file, subset_size):\n",
        "    with open(full_file, \"rb\") as full_file:\n",
        "        with open(subset_file, \"wb\") as subset_file:\n",
        "            # Write the header\n",
        "            header = full_file.readline()\n",
        "            subset_file.write(header)\n",
        "\n",
        "            # Write a subset of vectors\n",
        "            for _ in range(subset_size):\n",
        "                line = full_file.readline()\n",
        "                subset_file.write(line)\n",
        "\n",
        "# Create the subset file\n",
        "create_subset(full_vectors_loc, subset_vectors_loc, subset_size)\n",
        "\n",
        "# Load the subset of word vectors into SpaCy\n",
        "lang = \"en\"\n",
        "nlp = spacy.blank(lang)\n",
        "with open(subset_vectors_loc, \"rb\") as file_:\n",
        "    header = file_.readline()\n",
        "    nr_row, nr_dim = header.split()\n",
        "    nlp.vocab.reset_vectors(width=int(nr_dim))\n",
        "    for line in file_:\n",
        "        line = line.rstrip().decode(\"utf8\")\n",
        "        pieces = line.rsplit(\" \", int(nr_dim))\n",
        "        word = pieces[0]\n",
        "        vector = np.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "        nlp.vocab.set_vector(word, vector)\n",
        "\n",
        "file_path = \"/content/subset_vectors.vec\"\n",
        "\n",
        "# Open the file and count the number of lines\n",
        "with open(file_path, 'r') as file:\n",
        "    num_lines = sum(1 for line in file)\n",
        "\n",
        "print(\"Number of lines in\", file_path, \":\", num_lines)"
      ],
      "metadata": {
        "id": "PAKi-w04v5QE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a816ec-38e5-4bae-9537-922b8ebaffb1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines in /content/subset_vectors.vec : 5001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuvQpVLPjRaT",
        "outputId": "04545e15-b551-452e-ac12-e240efc068b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity btw doctor and patient  :- 0.6411671042442322\n"
          ]
        }
      ],
      "source": [
        "text = \"I lost his doctor in patient yesterday\"\n",
        "doc = nlp(text)\n",
        "print(\"similarity btw\",doc[3] , \"and\", doc[5],\" :-\", doc[3].similarity(doc[5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKn6YehgjRap"
      },
      "source": [
        "# Part  2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGY9RoeGjRaq"
      },
      "source": [
        "Steps involved :-\n",
        "1. Loading required library\n",
        "2. Setting up the parameters for traning\n",
        "3. Traning and saving the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f33b-LXvjRar"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import random # random function for to remove bais in Traning Data\n",
        "\n",
        "# for batch parsing\n",
        "from spacy.util import minibatch, compounding\n",
        "\n",
        "\n",
        "# For evaluateing the model from testing set\n",
        "from spacy.training import *\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cW3dDFWgjRau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "479bd5f2-1d76-420e-b2e9-ddce80fcaad2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    # add labels that will be involved in training\\n    for _, annotations in TRAIN_DATA:\\n         for ent in annotations.get(\\'entities\\'):\\n            ner.add_label(ent[2])\\n\\n    examples = []\\n\\n    for text, annotations in TRAIN_DATA:\\n        doc = nlp(text)\\n        examples.append(Example.from_dict(doc, annotations))\\n\\n    other_pipes = [pipe for pipe in modiner.pipe_names if pipe != \\'ner\\']\\n    with modiner.disable_pipes(*other_pipes):  # only train NER\\n        optimizer = modiner.begin_training()\\n        for itn in range(iterations):\\n            print(\"Starting iteration \" + str(itn))\\n            random.shuffle(TRAIN_DATA)\\n            losses = {}\\n            #batches = minibatch(TRAIN_DATA, size=compounding(2.0, 16.0, 1.01))\\n            #size_of_batches = sys.getsizeof(batches)\\n            #print(\"Size of batches:\", size_of_batches, \"bytes\")\\n            c = 1\\n            for example in tqdm(examples):\\n                print(example)\\n                nlp.update(\\n                    [example],  \\n                    drop=0.5,  \\n                    sgd=optimizer,\\n                    losses=losses)\\n                print(losses)\\n            c += 1\\n\\n            # Evaluating the Current Model Score on test data\\n            results = evaluate(modiner, TEST_DATA)\\n            print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\\n\\n\\n\\n            # loading previous best saved model in start of traning\\n            if f1score == 0.00:\\n                try:\\n                    pnlp = spacy.load(modelName)\\n                    result = evaluate(pnlp, TEST_DATA) # calling evaluate function\\n                    f1score = result[\"ents_f\"]\\n                except:\\n                    print(\"Previous Model not found\")\\n\\n            print(\"Best Sccore :- \",f1score)\\n            print(\"------------------------------------\")\\n            # finding out the best score\\n            if f1score < results[\"ents_f\"]:\\n                f1score = results[\"ents_f\"]\\n\\n                # Save our trained Model if the score if grater than best score else no change in previous model\\n                modiner.to_disk(modelName)\\n\\n    print(\"-----Best Model is Saved-----\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "def train_spacy(TRAIN_DATA,TEST_DATA,iterations,droprate = 0.5,modelName = \"modelTrained\"):\n",
        "\n",
        "    lang=\"en\"\n",
        "    vectors_loc = \"/content/subset_vectors.vec\"\n",
        "    modiner = spacy.blank(lang)\n",
        "    with open(vectors_loc, \"rb\") as file_:\n",
        "        header = file_.readline()\n",
        "        nr_row, nr_dim = header.split()\n",
        "        modiner.vocab.reset_vectors(width=int(nr_dim))\n",
        "        for line in file_:\n",
        "            line = line.rstrip().decode(\"utf8\")\n",
        "            pieces = line.rsplit(\" \", int(nr_dim))\n",
        "            word = pieces[0]\n",
        "            vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "            modiner.vocab.set_vector(word, vector)  # add the vectors to the vocab\n",
        "    ner = nlp.create_pipe(\"ner\")\n",
        "    if 'ner' not in modiner.pipe_names:\n",
        "        modiner.add_pipe(\"ner\", last=True)\n",
        "\n",
        "    # setting up f1score\n",
        "    f1score = 0.0000\n",
        "\n",
        "    from spacy.training import Example\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "        for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    examples = []\n",
        "\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        doc = nlp(text)\n",
        "        examples.append(Example.from_dict(doc, annotations))\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(100):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            for example in tqdm(examples):\n",
        "                nlp.update(\n",
        "                    [example],\n",
        "                    drop=0.5,\n",
        "                    sgd=optimizer,\n",
        "                    losses=losses)\n",
        "            print(losses)\n",
        "\n",
        "'''\n",
        "    # add labels that will be involved in training\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    examples = []\n",
        "\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        doc = nlp(text)\n",
        "        examples.append(Example.from_dict(doc, annotations))\n",
        "\n",
        "    other_pipes = [pipe for pipe in modiner.pipe_names if pipe != 'ner']\n",
        "    with modiner.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = modiner.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            print(\"Starting iteration \" + str(itn))\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            #batches = minibatch(TRAIN_DATA, size=compounding(2.0, 16.0, 1.01))\n",
        "            #size_of_batches = sys.getsizeof(batches)\n",
        "            #print(\"Size of batches:\", size_of_batches, \"bytes\")\n",
        "            c = 1\n",
        "            for example in tqdm(examples):\n",
        "                print(example)\n",
        "                nlp.update(\n",
        "                    [example],\n",
        "                    drop=0.5,\n",
        "                    sgd=optimizer,\n",
        "                    losses=losses)\n",
        "                print(losses)\n",
        "            c += 1\n",
        "\n",
        "            # Evaluating the Current Model Score on test data\n",
        "            results = evaluate(modiner, TEST_DATA)\n",
        "            print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
        "\n",
        "\n",
        "\n",
        "            # loading previous best saved model in start of traning\n",
        "            if f1score == 0.00:\n",
        "                try:\n",
        "                    pnlp = spacy.load(modelName)\n",
        "                    result = evaluate(pnlp, TEST_DATA) # calling evaluate function\n",
        "                    f1score = result[\"ents_f\"]\n",
        "                except:\n",
        "                    print(\"Previous Model not found\")\n",
        "\n",
        "            print(\"Best Sccore :- \",f1score)\n",
        "            print(\"------------------------------------\")\n",
        "            # finding out the best score\n",
        "            if f1score < results[\"ents_f\"]:\n",
        "                f1score = results[\"ents_f\"]\n",
        "\n",
        "                # Save our trained Model if the score if grater than best score else no change in previous model\n",
        "                modiner.to_disk(modelName)\n",
        "\n",
        "    print(\"-----Best Model is Saved-----\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xRX87HJnjRay"
      },
      "outputs": [],
      "source": [
        "from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "def evaluate(ner_model, examples):\n",
        "    scorer = Scorer()\n",
        "    for input_, annotations in examples:\n",
        "        tags = []\n",
        "        # loading text\n",
        "        doc_gold_text = ner_model.make_doc(input_)\n",
        "\n",
        "        # loading all tags for that text\n",
        "        for ent in annotations.get('entities'):\n",
        "            start, end, label = ent\n",
        "            tags.append((start, end, label))\n",
        "\n",
        "        # Evaluating the tags\n",
        "        gold = Example.from_dict(doc_gold_text, {\"entities\": tags})\n",
        "        pred_value = ner_model(input_)\n",
        "        scorer.score(pred_value, gold)\n",
        "\n",
        "    return scorer.scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Yz4LfssbjRa0"
      },
      "outputs": [],
      "source": [
        "def loadNERModel(modelName = \"modelTrained\"):\n",
        "    nlp = spacy.load(modelName)\n",
        "    return nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "guqS2EGBjRa3"
      },
      "outputs": [],
      "source": [
        "def score(model,TEST_DATA):\n",
        "    result = evaluate(model, TEST_DATA) # calling evaluate function\n",
        "    f1score = result[\"ents_f\"]\n",
        "    precision = result[\"ents_p\"]\n",
        "    recall = result[\"ents_r\"]\n",
        "    print(\"F1 score of Model is :-\",f1score)\n",
        "    print(\"Precision of Model is :-\",precision)\n",
        "    print(\"Recall of Model is :-\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.training import Example\n",
        "modelName = \"modelTrained\"\n",
        "lang=\"en\"\n",
        "vectors_loc = \"/content/subset_vectors.vec\"\n",
        "modiner = spacy.blank(lang)\n",
        "with open(vectors_loc, \"rb\") as file_:\n",
        "    header = file_.readline()\n",
        "    nr_row, nr_dim = header.split()\n",
        "    modiner.vocab.reset_vectors(width=int(nr_dim))\n",
        "    for line in file_:\n",
        "        line = line.rstrip().decode(\"utf8\")\n",
        "        pieces = line.rsplit(\" \", int(nr_dim))\n",
        "        word = pieces[0]\n",
        "        vector = numpy.asarray([float(v) for v in pieces[1:]], dtype=\"f\")\n",
        "        modiner.vocab.set_vector(word, vector)  # add the vectors to the vocab\n",
        "ner = nlp.create_pipe(\"ner\")\n",
        "if 'ner' not in modiner.pipe_names:\n",
        "    modiner.add_pipe(\"ner\", last=True)\n",
        "\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get('entities'):\n",
        "      ner.add_label(ent[2])\n",
        "\n",
        "examples = []\n",
        "\n",
        "for text, annotations in TRAIN_DATA:\n",
        "    doc = nlp(text)\n",
        "    examples.append(Example.from_dict(doc, annotations))\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with modiner.disable_pipes(*other_pipes):  # only train NER\n",
        "    optimizer = modiner.begin_training()\n",
        "    for itn in range(1):\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        for example in tqdm(examples):\n",
        "            modiner.update(\n",
        "                [example],\n",
        "                drop=0.5,\n",
        "                losses=losses)\n",
        "        print(losses)\n",
        "        results = evaluate(modiner, TEST_DATA)\n",
        "        #print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
        "        if f1score == 0.00:\n",
        "            try:\n",
        "                pnlp = spacy.load(modelName)\n",
        "                result = evaluate(pnlp, TEST_DATA) # calling evaluate function\n",
        "                f1score = result[\"ents_f\"]\n",
        "            except:\n",
        "                print(\"Previous Model not found\")\n",
        "\n",
        "        print(\"Best Sccore :- \",f1score)\n",
        "        print(\"------------------------------------\")\n",
        "        if f1score < results[\"ents_f\"]:\n",
        "            f1score = results[\"ents_f\"]\n",
        "            modiner.to_disk(modelName)\n",
        "\n",
        "    print(\"-----Best Model is Saved-----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "fsoJwEDjHCB2",
        "outputId": "20e831ce-01ac-4624-cc54-646df2c5a7ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36418/36418 [22:23<00:00, 27.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ner': 81943.41137613842}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "__init__() takes exactly 2 positional arguments (1 given)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4a4460eaa216>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                 losses=losses)\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodiner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current Score :-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ents_f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Precision  :-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ents_p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Recall  :-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ents_r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf1score\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.00\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-30ba19657701>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ner_model, examples)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Evaluating the tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_gold_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mner_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/training/example.pyx\u001b[0m in \u001b[0;36mspacy.training.example.Example.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 2 positional arguments (1 given)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZijYn1k6pJvL"
      },
      "outputs": [],
      "source": [
        "# traning the model with 100 iterations\n",
        "\n",
        "\n",
        "train_spacy(TRAIN_DATA,TEST_DATA, 1,droprate = 0.55, modelName = \"CrimeNER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afOFw7bCjRbB"
      },
      "outputs": [],
      "source": [
        "# loading the saved model\n",
        "pnlp = loadNERModel(\"CrimeNER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQLM6egTpJvL",
        "outputId": "fe4812f7-265f-4aae-fc2b-f7f7d5cb747f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score of Model is :- 86.47551444580847\n",
            "Precision of Model is :- 87.0393931979447\n",
            "Recall of Model is :- 85.91889476607976\n"
          ]
        }
      ],
      "source": [
        "# calculating the score of the model\n",
        "score(pnlp,TEST_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq3fKUBujRbI"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvywkBOA9AY2",
        "outputId": "1f7365cc-fc1b-403e-865b-547d44f35bcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">he was \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    killed\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " due to \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    harassment\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('he was killed due to harassment')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OHvJTkjpJvM",
        "outputId": "14dde88b-0d80-4299-daba-40a9811b4df7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A woman was \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    assault\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " by two men near \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shahdara\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('A woman was assault by two men near Shahdara')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tyb4RAWpJvM",
        "outputId": "78e8a86d-01a1-42d3-b917-18c90ec5379c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Pooja\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-per</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    I\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
              "</mark>\n",
              " was near \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Domino-pizza\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-org</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Pinjore\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              " a man on bike \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    snatched\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " my purse</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('My name is Pooja I was near Domino-pizza in Pinjore a man on bike snatched my purse')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KnyiH09pJvM",
        "outputId": "d54f27e0-6a90-4b43-fc26-00ae70e417ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amit\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-per</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    I\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
              "</mark>\n",
              " saw a woman \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    killing\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " a dog on \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    15th\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-tim</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    july\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-tim</span>\n",
              "</mark>\n",
              " near \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kalujhanda\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('My name is Amit I saw a woman killing a dog on 15th july near Kalujhanda')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00JgazqIpJvN",
        "outputId": "c8f23d6d-06f4-4e51-a91e-be9a04f7a47f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A car \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hit\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " me at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mansarovar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Park\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">I-geo</span>\n",
              "</mark>\n",
              " at 5pm wraped</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('A car hit me at Mansarovar Park at 5pm wraped')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqsoj-LLpJvN",
        "outputId": "10afde33-b60c-44f3-f2ed-c04ec6a69631"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Yesterday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-tim</span>\n",
              "</mark>\n",
              " there was incident of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    theft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-Crime</span>\n",
              "</mark>\n",
              " near my house</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('Yesterday there was incident of theft near my house')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMsA-3SmpJvO",
        "outputId": "e51273d0-6e1a-44ef-9255-3e4ff983881d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A man slapped a girl in the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sadar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
              "</mark>\n",
              " market</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('A man slapped a girl in the Sadar market')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTmSz1WApJvO",
        "outputId": "56d70c47-b5ea-428e-f434-a122ee14cacf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Shreya\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  warnings.warn(Warnings.W006)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">  </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhOiJ5nTpJvO"
      },
      "outputs": [],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLYlUpmVpJvP"
      },
      "outputs": [],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55BBsXt2pJvP"
      },
      "outputs": [],
      "source": [
        "testcase = pnlp('  ')\n",
        "displacy.render(testcase, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX0sxFLCpJvP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0begjTbspJvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOW7ZtPupJvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_LJMq_TpJvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axuRCCUGpJvR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIWrMATnpJvR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnj-YF-4pJvR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}