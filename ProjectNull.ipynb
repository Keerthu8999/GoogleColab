{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVC5woS664KjfPPcksT/5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keerthu8999/GoogleColab/blob/main/ProjectNull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eYkzp9i-kwxw"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "from sklearn.metrics import classification_report\n",
        "from CoNLL2Spacy import *\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    file = open(\"/content/Crimetest.txt\", \"r\",encoding = \"utf-8\")\n",
        "    valList = []\n",
        "    for line in file:\n",
        "        valList.append(line[:-1])\n",
        "    test_data = conll2spacy(valList)  # Your testing data\n",
        "    file = open(\"/content/Crimetrain.txt\", \"r\",encoding = \"utf-8\")\n",
        "    trainList = []\n",
        "    for line in file:\n",
        "        trainList.append(line[:-1])\n",
        "    train_data = conll2spacy(trainList)\n",
        "    return train_data, test_data\n"
      ],
      "metadata": {
        "id": "CFzXJvUjS8Y_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spacy(train_data, test_data, iterations=20, dropout=0.5, model_name=\"modelTrained\"):\n",
        "    nlp = spacy.blank(\"en\")  # Load English language model\n",
        "    ner = nlp.add_pipe(\"ner\", last=True)  # Add Named Entity Recognition pipeline\n",
        "\n",
        "    # Add labels to the NER pipeline\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get(\"entities\"):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # Convert training data to spaCy Example objects\n",
        "    train_examples = []\n",
        "    for text, annotations in train_data:\n",
        "        train_examples.append(Example.from_dict(nlp.make_doc(text), annotations))\n",
        "\n",
        "    # Disable other pipelines during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            random.shuffle(train_examples)\n",
        "            losses = {}\n",
        "            for example in train_examples:\n",
        "                nlp.update([example], drop=dropout, losses=losses)\n",
        "            print(\"Iteration:\", itn, \"Losses:\", losses)\n",
        "\n",
        "    # Save the trained model\n",
        "    nlp.to_disk(model_name)"
      ],
      "metadata": {
        "id": "tO2Foe9pTVW3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_spacy(model_name, test_data):\n",
        "    nlp = spacy.load(model_name)  # Load trained model\n",
        "    scorer = Scorer()\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    for text, annotations in test_data:\n",
        "        doc = nlp(text)\n",
        "        true_entities = [ent for _, ent in annotations.get(\"entities\")]\n",
        "        pred_entities = [ent.label_ for ent in doc.ents]\n",
        "        true_labels.extend(true_entities)\n",
        "        pred_labels.extend(pred_entities)\n",
        "        example = Example.from_dict(doc, annotations)\n",
        "        scorer.score([example])  # Update scorer with the current example\n",
        "    print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "hZ7V_0P9TYq1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_data, test_data = load_data()\n",
        "    train_spacy(train_data, test_data)\n",
        "    evaluate_spacy(\"modelTrained\", test_data)"
      ],
      "metadata": {
        "id": "bFOAuFJ3Tbg8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eFQmZqkTdfu",
        "outputId": "a6c02b80-cd8f-4ea7-d0e4-ecafd2fe7199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 Losses: {'ner': 81852.24288907254}\n",
            "Iteration: 1 Losses: {'ner': 64739.57049821249}\n"
          ]
        }
      ]
    }
  ]
}